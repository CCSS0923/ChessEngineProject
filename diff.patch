--- a/engine/include/engine/NNWrapper.h
+++ b/engine/include/engine/NNWrapper.h
@@ -1,26 +1,38 @@
 #pragma once

 #include <array>
 #include <mutex>
 #include <string>
 #include <vector>

 #include "NNBoardTensor.h" // boardToTensor()
 #include "board.h"         // Board 클래스
 #include <torch/script.h>

 namespace chess {

 struct NNResult {
   std::array<float, 4096> policy{};
   float value = 0.0f;
   bool ok = false;
 };

 class NNWrapper {
 public:
   static NNWrapper &instance();

   void init(const std::string &modelPath, int deviceIndex = -1);
   bool isReady() const;
+
+  // 치명적 오류 후 NN 사용 중지
+  void disable();
+
+  // 마지막 에러 메시지 조회(디버깅용)
+  const std::string &lastError() const;

   // 기존: tensor 입력 버전
   NNResult evaluate(const uint8_t *inputCHW);

   // 새로 추가: Board → policy vector
   std::vector<float> Evaluate(const Board &board);

 private:
   NNWrapper();
   ~NNWrapper() = default;
@@ -30,9 +42,11 @@

   mutable std::mutex m_mutex;
   torch::jit::script::Module m_module;
   torch::Device m_device;
   bool m_ready = false;
+  std::string m_lastError;
 };

 } // namespace chess

--- a/engine/src/NNWrapper.cpp
+++ b/engine/src/NNWrapper.cpp
@@ -1,7 +1,6 @@
 #include "engine/NNWrapper.h"
 #include "engine/NNBoardTensor.h"
 #include "engine/board.h"
-
 #include <cstring>
 #include <fstream>
 #include <iostream>
@@ -17,16 +16,49 @@

 NNWrapper::NNWrapper() : m_device(torch::kCPU), m_ready(false) {}

-bool NNWrapper::isReady() const { return m_ready; }
+bool NNWrapper::isReady() const { return m_ready; }
+
+void NNWrapper::disable() {
+  std::lock_guard<std::mutex> lock(m_mutex);
+  m_ready = false;
+}
+
+const std::string &NNWrapper::lastError() const {
+  return m_lastError;
+}

 void NNWrapper::init(const std::string &modelPath, int deviceIndex) {
   std::lock_guard<std::mutex> lock(m_mutex);
   m_ready = false;
+  m_lastError.clear();

   // 1) 먼저 파일 존재 / 열기 확인
   std::ifstream ifs(modelPath, std::ios::binary);
   if (!ifs) {
-    std::cerr << "[NNWrapper] model not found: " << modelPath << std::endl;
+    m_lastError = "model not found: " + modelPath;
+    std::cerr << "[NNWrapper] " << m_lastError << std::endl;
     return;
   }

   try {
@@ -36,38 +68,109 @@
       m_device = torch::Device(torch::kCUDA, deviceIndex);
       std::cout << "[NNWrapper] Using CUDA:" << deviceIndex << "\n";
     } else {
       m_device = torch::Device(torch::kCPU);
       std::cout << "[NNWrapper] Using CPU\n";
     }

     // 3) 경로 기반 오버로드 대신, 스트림 기반 오버로드 사용
     m_module = torch::jit::load(ifs, m_device);
     m_module.eval();
     m_ready = true;
+    m_lastError.clear();

     std::cout << "[NNWrapper] Model loaded OK\n";
   } catch (const c10::Error &e) {
-    std::cerr << "[NNWrapper] load error: " << e.what() << std::endl;
+    m_lastError = e.what_without_backtrace();
+    std::cerr << "[NNWrapper] load error (c10): " << m_lastError << std::endl;
     m_ready = false;
+  } catch (const std::exception &e) {
+    m_lastError = e.what();
+    std::cerr << "[NNWrapper] load error (std): " << m_lastError << std::endl;
+    m_ready = false;
+  } catch (...) {
+    m_lastError = "unknown exception in init()";
+    std::cerr << "[NNWrapper] load error: " << m_lastError << std::endl;
+    m_ready = false;
   }
 }

 NNResult NNWrapper::evaluate(const uint8_t *inputCHW) {
   NNResult result;
   if (!m_ready)
     return result;

   try {
     auto options_u8 =
         torch::TensorOptions().dtype(torch::kUInt8).device(torch::kCPU);
@@ -79,22 +182,68 @@

     std::vector<torch::jit::IValue> inputs;
     inputs.emplace_back(input);

     torch::jit::IValue out = m_module.forward(inputs);
-    auto tup = out.toTuple();
-
-    auto policy = tup->elements()[0].toTensor().to(torch::kCPU).view({4096});
-    auto value = tup->elements()[1].toTensor().to(torch::kCPU).view({1});
-
-    for (int i = 0; i < 4096; ++i)
-      result.policy[i] = policy[i].item<float>();
-
-    result.value = value[0].item<float>();
-    result.ok = true;
-  } catch (...) {
-    std::cerr << "[NNWrapper] evaluate failed\n";
+
+    if (!out.isTuple()) {
+      m_lastError = "model output is not a tuple";
+      std::cerr << "[NNWrapper] " << m_lastError << "\n";
+      m_ready = false;
+      return result;
+    }
+
+    auto tup = out.toTuple();
+    if (!tup || tup->elements().size() < 2) {
+      m_lastError = "model output tuple size < 2";
+      std::cerr << "[NNWrapper] " << m_lastError << "\n";
+      m_ready = false;
+      return result;
+    }
+
+    auto policyI = tup->elements()[0];
+    auto valueI  = tup->elements()[1];
+
+    if (!policyI.isTensor() || !valueI.isTensor()) {
+      m_lastError = "model output elements are not tensors";
+      std::cerr << "[NNWrapper] " << m_lastError << "\n";
+      m_ready = false;
+      return result;
+    }
+
+    auto policyT = policyI.toTensor().to(torch::kCPU);
+    auto valueT  = valueI.toTensor().to(torch::kCPU);
+
+    if (!policyT.defined() || policyT.numel() != 4096) {
+      m_lastError = "policy tensor has invalid shape, numel=" +
+                    std::to_string(policyT.numel());
+      std::cerr << "[NNWrapper] " << m_lastError << "\n";
+      m_ready = false;
+      return result;
+    }
+
+    policyT = policyT.view({4096});
+    valueT  = valueT.view(-1);
+
+    if (!valueT.defined() || valueT.numel() < 1) {
+      m_lastError = "value tensor has invalid shape";
+      std::cerr << "[NNWrapper] " << m_lastError << "\n";
+      m_ready = false;
+      return result;
+    }
+
+    for (int i = 0; i < 4096; ++i)
+      result.policy[i] = policyT[i].item<float>();
+
+    result.value = valueT[0].item<float>();
+    result.ok = true;
+  } catch (const c10::Error &e) {
+    m_lastError = e.what_without_backtrace();
+    std::cerr << "[NNWrapper] evaluate failed (c10): " << m_lastError << "\n";
+    m_ready = false;
+  } catch (const std::exception &e) {
+    m_lastError = e.what();
+    std::cerr << "[NNWrapper] evaluate failed (std): " << m_lastError << "\n";
+    m_ready = false;
+  } catch (...) {
+    m_lastError = "unknown exception in evaluate()";
+    std::cerr << "[NNWrapper] evaluate failed (unknown)\n";
+    m_ready = false;
   }

   return result;
 }
@@ -118,4 +267,4 @@
   return out;
 }

-} // namespace chess
+} // namespace chess

--- a/engine/src/Engine.cpp
+++ b/engine/src/Engine.cpp
@@ -1,6 +1,7 @@
 #include "Engine.h"
 #include "NNWrapper.h"
 #include "movegen.h"
+#include "search.h"

 #include <sstream>

@@ -54,27 +55,73 @@
       b.loadFEN(fenPart);
   }
 }

 std::string Engine::SearchBestMove(NNWrapper &nn, const std::string &goCmd) {
-  int depth = parseDepthFromGo(goCmd, 4);
-  (void)depth;
+  int depth = parseDepthFromGo(goCmd, 4);

   std::vector<Move> moves;
   MoveGen::generate(b, moves);

   if (moves.empty())
     return "0000";

-  // ★★★ 수정 후 정상 작동: Board → NNWrapper.Evaluate(Board)
-  std::vector<float> policy = nn.Evaluate(b);
-
-  float bestScore = -1e30f;
-  Move best = moves.front();
-
-  for (const auto &m : moves) {
-    if (m.from < 0 || m.from >= 64 || m.to < 0 || m.to >= 64)
-      continue;
-
-    float s = policy[m.from * 64 + m.to];
-    if (s > bestScore) {
-      bestScore = s;
-      best = m;
-    }
-  }
-
-  return best.toUciString();
+  // ---------------------------
+  // 1) NN 사용 시도
+  // ---------------------------
+  bool nnOk = nn.isReady();
+  std::vector<float> policy;
+
+  if (nnOk) {
+    policy = nn.Evaluate(b);
+
+    if (policy.size() != 4096) {
+      nnOk = false;
+    } else {
+      bool allZero = true;
+      for (float v : policy) {
+        if (v != 0.0f) {
+          allZero = false;
+          break;
+        }
+      }
+      if (allZero)
+        nnOk = false;
+    }
+  }
+
+  Move best = moves.front();
+
+  if (nnOk) {
+    float bestScore = -1e30f;
+
+    for (const auto &m : moves) {
+      if (m.from < 0 || m.from >= 64 || m.to < 0 || m.to >= 64)
+        continue;
+
+      const int idx = m.from * 64 + m.to;
+      if (idx < 0 || static_cast<size_t>(idx) >= policy.size())
+        continue;
+
+      float s = policy[static_cast<size_t>(idx)];
+      if (s > bestScore) {
+        bestScore = s;
+        best = m;
+      }
+    }
+
+    // NN이 준비됐는데도 유효한 move를 못 찾았으면 폴백
+    if (best.toUciString() != "0000")
+      return best.toUciString();
+  }
+
+  // ---------------------------
+  // 2) NN 실패 → searchBest 폴백
+  // ---------------------------
+  Board tmp = b;
+  best = searchBest(tmp, depth);
+
+  // searchBest가 null move를 줄 가능성 방어
+  if (best.from < 0 || best.from >= 64 || best.to < 0 || best.to >= 64) {
+    if (!moves.empty())
+      best = moves.front();
+    else
+      return "0000";
+  }
+
+  return best.toUciString();
 }

 } // namespace chess
